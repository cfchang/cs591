{
 "metadata": {
  "name": "",
  "signature": "sha256:45a21f85638ab01809535504173ac63950590f01567deb4a6a5053056c3d1483"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Beating the Random Acts of Pizza Benchmark\n",
      "##Day 2 of the [Beat 5 Kaggle Becnhmarks in 5 Days Challenge](https://www.kaggle.com/forums/t/10062/beat-5-kaggle-benchmarks-in-5-days-challenge).\n",
      "\n",
      "# The [Random Acts of Pizza](https://www.kaggle.com/c/random-acts-of-pizza) competition is about predicting when a request for a free pizza on the Random Acts of Pizza sub-reddit is granted. The benchmark is simply guessing that no pizzas are given (or all). This results in an AUC score of 50.\n",
      "\n",
      "# To beat the AUC = 50 benchmark with a simple model, I first looked at the training and test data to find simple features. I decided to use the word counts of the request title and comment text, as longer comments might be skipped by readers.\n",
      "\n",
      "# To build the model I first extracted only the desired fields from the original JSON files with jq and used json2csv to write out CSV\n",
      "\n",
      "# I then built a very basic random forest model using the default settings in scikit-learn. With a 80/20 training/test split I achieved a local AUC of about 0.52 (single validation). Using the entire training set to build a random forest, I was able to score an AUC of 0.51274 on the competition leaderboard.\n",
      "\n",
      "# Not great, but not bad for a very simple model.\n",
      "import json\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import sys\n",
      "\n",
      "\n",
      "def unistring(s):\n",
      "    \"\"\"Encodes our Unicode string to ASCII, then back to Unicode.\n",
      "    In the translation, we ignore all unknown characters, which removes\n",
      "    all of the non-ASCII characters that break our string parsing.\n",
      "    \"\"\"\n",
      "    return str(s).encode(\"ascii\", \"ignore\").decode()\n",
      "\n",
      "\n",
      "def process_data(data_json, key1, renamed1, key2, renamed2, key3, renamed3,\n",
      "                 key4, renamed4, key5, renamed5, key6=\"\", renamed6=\"\"):\n",
      "    \"\"\"Converts our list of dictionaries to a dictionary of lists,\n",
      "    while processing some of the data points (e.g. converting number strings\n",
      "    to ints and float, as well as lowercasing strings). Also uses renamed keys\n",
      "    instead of the very long default ones.\n",
      "    \"\"\"\n",
      "    val1 = []\n",
      "    val2 = []\n",
      "    val3 = []\n",
      "    val4 = []\n",
      "    val5 = []\n",
      "    val6 = []\n",
      "    for d in data_json:\n",
      "        val1.append(d[key1])\n",
      "        val2.append(float(d[key2]))\n",
      "        val3.append(int(d[key3]))\n",
      "        val4.append(d[key4].lower())\n",
      "        val5.append(d[key5].lower())\n",
      "        if key6 is not \"\":\n",
      "            val6.append(str(d[key6]) == \"true\" or str(d[key6]) == \"True\")\n",
      "    return {renamed1: val1,\n",
      "            renamed2: val2,\n",
      "            renamed3: val3,\n",
      "            renamed4: val4,\n",
      "            renamed5: val5,\n",
      "            renamed6: val6}\n",
      "\n",
      "\n",
      "def get_best_fit_poly_coeffs(data_dict, x, y, deg):\n",
      "    \"\"\"Finds the coefficients of the polynomial function for the best fit line.\n",
      "    \"\"\"\n",
      "    coeffs = np.polyfit(x=data_dict[x], y=data_dict[y], deg=deg)\n",
      "    return coeffs\n",
      "\n",
      "\n",
      "def scatter_plot(data_dict):\n",
      "    \"\"\"Visualizes account age versus karma on the x and y axes, and whether\n",
      "    or not the requester was given a pizza as the green or red point color.\n",
      "    \"\"\"\n",
      "    for i in range(len(data_dict[\"age\"])):\n",
      "        formatting = \".\" + (\"g\" if data_dict[\"result\"][i] else \"r\")\n",
      "        plt.plot(data_dict[\"age\"][i], data_dict[\"karma\"][i], formatting)\n",
      "    coeffs = get_best_fit_poly_coeffs(data_dict, \"age\", \"karma\", 1)\n",
      "    poly = np.poly1d(coeffs)\n",
      "    plt.plot(data_dict[\"age\"], poly(data_dict[\"age\"]))\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def will_reciprocate(data_dict, index):\n",
      "    \"\"\"Searches the text of the request for phrases that suggest a promise to\n",
      "    give pizza to someone else. data_dict is a dictionary of lists,and any given\n",
      "    index in the lists corresponds to the same post for different keys.\n",
      "    \"\"\"\n",
      "    title = data_dict[\"title\"][index]\n",
      "    body = data_dict[\"body\"][index]\n",
      "    phrases = [\"pay it forward\", \"return the favor\", \"reciprocate\"]\n",
      "    for p in phrases:\n",
      "        if p in title or p in body:\n",
      "            return True\n",
      "    return False\n",
      "\n",
      "\n",
      "def print_data(data_dict):\n",
      "    \"\"\"Prints the data for examining or debugging purposes.\n",
      "    \"\"\"\n",
      "    print(\"id, age, karma, reciprocal, result\")\n",
      "    for i in range(len(data_dict[\"id\"])):\n",
      "        print(\n",
      "            data_dict[\"id\"][i],\n",
      "            data_dict[\"age\"][i],\n",
      "            data_dict[\"karma\"][i],\n",
      "            will_reciprocate(data_dict, i),\n",
      "            data_dict[\"result\"][i]\n",
      "        )\n",
      "\n",
      "\n",
      "def train_acc(data_train, coeffs, multiplier):\n",
      "    \"\"\"Determines the accuracy of a set of coefficients\n",
      "    (with a multiplier) on the training data.\n",
      "    \"\"\"\n",
      "    poly = np.poly1d([i*multiplier for i in coeffs])\n",
      "    predictions_train = [(poly(data_train[\"age\"][i]) < data_train[\"karma\"][i])\n",
      "                         or will_reciprocate(data_train, i)\n",
      "                         for i in range(len(data_train[\"id\"]))]\n",
      "    correct = 0\n",
      "    for i in range(len(predictions_train)):\n",
      "        if predictions_train[i] == data_train[\"result\"][i]:\n",
      "            correct += 1\n",
      "    accuracy = correct / len(predictions_train) * 100\n",
      "    return accuracy\n",
      "\n",
      "\n",
      "def sweep_coeff(data_train, coeffs):\n",
      "    \"\"\"Sweep the coefficients to see which multiplier gives the best accuracy.\n",
      "    \"\"\"\n",
      "    best_m = 1\n",
      "    best_a = 0\n",
      "    for m in np.arange(0.0, 100.0, 0.1):\n",
      "        acc = train_acc(data_train, coeffs, m)\n",
      "        if acc > best_a:\n",
      "            best_m = m\n",
      "            best_a = acc\n",
      "            print(\"New best multiplier:\", best_m, \"with an accuracy of\", best_a)\n",
      "    return [i*best_m for i in coeffs]\n",
      "\n",
      "\n",
      "def main(argv):\n",
      "    \"\"\"The main program itself. Imports JSON data as a list of dictionaries,\n",
      "    each of which is a data point (a pizza request). Then makes predictions\n",
      "    as to whether or not the request would be fulfilled based on whether or\n",
      "    not they offered to reciprocate, as well as whether or not they had more\n",
      "    karma than the corresponding point on the best-fit line.\n",
      "    \"\"\"\n",
      "    with open(\"train.json\") as open_file:\n",
      "        json_train = json.loads(unistring(open_file.read()))\n",
      "    print(len(json_train), \"training data points\")\n",
      "    data_train = process_data(json_train,\n",
      "                              \"request_id\",\n",
      "                              \"id\",\n",
      "                              \"requester_account_age_in_days_at_request\",\n",
      "                              \"age\",\n",
      "                              \"requester_upvotes_minus_downvotes_at_request\",\n",
      "                              \"karma\",\n",
      "                              \"request_title\",\n",
      "                              \"title\",\n",
      "                              \"request_text_edit_aware\",\n",
      "                              \"body\",\n",
      "                              \"requester_received_pizza\",\n",
      "                              \"result\")\n",
      "    with open(\"test.json\") as open_file:\n",
      "        json_test = json.loads(unistring(open_file.read()))\n",
      "    print(len(json_test), \"testing data points\")\n",
      "    data_test = process_data(json_test,\n",
      "                             \"request_id\",\n",
      "                             \"id\",\n",
      "                             \"requester_account_age_in_days_at_request\",\n",
      "                             \"age\",\n",
      "                             \"requester_upvotes_minus_downvotes_at_request\",\n",
      "                             \"karma\",\n",
      "                             \"request_title\",\n",
      "                             \"title\",\n",
      "                             \"request_text_edit_aware\",\n",
      "                             \"body\")\n",
      "    # print_data(data_dict)\n",
      "    # scatter_plot(data_dict)\n",
      "    coeffs = get_best_fit_poly_coeffs(data_train, \"age\", \"karma\", 1)\n",
      "    print(\"Initial coefficients:\", coeffs)\n",
      "    best_coeffs = sweep_coeff(data_train, coeffs)\n",
      "    poly = np.poly1d(best_coeffs)\n",
      "    print(\"Best coefficients:\", best_coeffs)\n",
      "\n",
      "    predictions_test = [(poly(data_test[\"age\"][i]) < data_test[\"karma\"][i])\n",
      "                        or will_reciprocate(data_test, i)\n",
      "                        for i in range(len(data_test[\"id\"]))]\n",
      "\n",
      "    with open(\"predictions.csv\", \"w\") as output:\n",
      "        output.write(\"request_id,requester_received_pizza\\n\")\n",
      "        for i in range(len(data_test[\"id\"])):\n",
      "            output.write(\"%s,%d\\n\" % (data_test[\"id\"][i], predictions_test[i]))\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main(sys.argv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(4040, 'training data points')\n",
        "(1631, 'testing data points')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Initial coefficients:', array([   3.33444719,  311.17444576]))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Best coefficients:', [3.3344471912561309, 311.17444575947081])"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import pandas as pd\n",
      "import pandas.io.data as web\n",
      "from pandas import Series, DataFrame\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib as mpl\n",
      "import seaborn as sns\n",
      "\n",
      "\n",
      "from datetime import datetime\n",
      "\n",
      "#pd.__version__\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "# COLS = [\"post_was_edited\",\n",
      "#         \"request_id\",\n",
      "#         \"requester_account_age_in_days_at_request\",\n",
      "#         \"requester_days_since_first_post_on_raop_at_request\",\n",
      "#         \"requester_number_of_comments_at_request\",\n",
      "#         \"requester_number_of_comments_in_raop_at_request\",\n",
      "#         \"requester_number_of_posts_at_request\",\n",
      "#         \"requester_number_of_posts_on_raop_at_request\",\n",
      "#         \"requester_number_of_subreddits_at_request\",\n",
      "#         \"requester_received_pizza\",\n",
      "#         \"requester_upvotes_minus_downvotes_at_request\",\n",
      "#         \"requester_upvotes_plus_downvotes_at_request\",\n",
      "#         \"request_title\",\n",
      "#         \"request_text_edit_aware\",\n",
      "#         \"request_text\",\n",
      "#         \"requester_upvotes_minus_downvotes_at_retrieval\",\n",
      "#         \"requester_account_age_in_days_at_retrieval\",\n",
      "#         \"requester_number_of_comments_at_retrieval\",\n",
      "#         \"requester_user_flair\",]\n",
      "\n",
      "# read the json into a pandas dataframe\n",
      "t = pd.read_json('train.json')\n",
      "\n",
      "afinnfile = open(\"AFINN-111.txt\")\n",
      "scores = {} \n",
      "for line in afinnfile:\n",
      "  term, score  = line.split(\"\\t\")  \n",
      "  scores[term] = int(score)\n",
      " \n",
      "desire = [\"friend\",\"party\",\"birthday\",\"boyfriend\",\"girlfriend\",\"date\",\"drinks\",\"drunk\",\"wasted\",\"invite\",\"invited\",\"celebrate\",\"celebrating\",\"game\",\"games\",\"movie\",\"beer\",\"crave\",\"craving\"]    \n",
      "family = [\"husband\",\"wife\",\"family\",\"parent\",\"parentsmother\",\"father\",\"mom\",\"mum\",\"son\",\"dad\",\"daughter\"]\n",
      "job = [\"job\",\"unemployment\",\"employment\",\"hire\",\"hired\",\"fired\",\"interview\",\"work\",\"paycheck\"]\n",
      "money = [\"money\",\"bill\",\"bills\",\"rent\",\"bank\",\"account\",\"paycheck\",\"due\",\"broke\",\"bills\",\"deposit\",\"cashdollar\",\"dollars\",\"bucks\",\"paid\",\"payed\",\"buy\",\"check\",\"spent\",\"financial\",\"poor\",\"loan\",\"credit\",\"budget\",\"day\",\"now\",\"time\",\"week\",\"until\",\"last\",\"month\"\n",
      ",\"tonight\",\"today\",\"next\",\"night\",\"when\",\"tomorrow\",\"first\",\"after\",\"while\",\"before\",\"long\",\"hour\",\"Friday\",\"ago\",\"still\",\"due\",\"past\",\"soon\",\"current\",\"years\",\"never\",\"till\",\"yesterday\",\"morning\",\"evening\"]\n",
      "student = [\"college\",\"student\",\"university\",\"finals\",\"study\",\"studying\",\"class\",\"semester\",\"school\",\"roommate\",\"project\",\"tuition\",\"dorm\"]\n",
      " \n",
      "# Create arrays for convenient storage\n",
      " \n",
      "sentiment = num.zeros(len(t))\n",
      "desire_vec = num.zeros(len(t))\n",
      "family_vec = num.zeros(len(t))\n",
      "job_vec = num.zeros(len(t))\n",
      "money_vec = num.zeros(len(t))\n",
      "student_vec = num.zeros(len(t))\n",
      "upvotes_vec = num.zeros(len(t))\n",
      "accountagerequest_vec = num.zeros(len(t))\n",
      "accountageretrieval_vec = num.zeros(len(t))\n",
      "commentsretrieval_vec = num.zeros(len(t))\n",
      "flair_vec = num.zeros(len(t))\n",
      "pizza_vec = num.zeros(len(t))\n",
      " \n",
      " \n",
      "# Extract interest variables from each record\n",
      " \n",
      "for i in range(len(t)):\n",
      "    text = t[i][\"request_text\"]\n",
      "#     upvotes = t[i][\"requester_upvotes_minus_downvotes_at_retrieval\"]\n",
      "#     accountagerequest = t[i][\"requester_account_age_in_days_at_request\"]\n",
      "#     accountageretrieval = t[i][\"requester_account_age_in_days_at_retrieval\"]\n",
      "#     commentsretrieval = t[i][\"requester_number_of_comments_at_retrieval\"]\n",
      "#     if t[i][\"requester_user_flair\"] == \"schroom\":\n",
      "#         flair = 1\n",
      "#     if t[i][\"requester_user_flair\"] == \"PIF\":\n",
      "#         flair = 2\n",
      "#     else:\n",
      "#         flair = 0  \n",
      "#     if t[i][\"requester_received_pizza\"] == True:\n",
      "#         pizza = 1\n",
      "#     else:\n",
      "#         pizza = 0\n",
      " \n",
      "#     #Compute sentiment for each text\n",
      " \n",
      "#     words = text.split()\n",
      "#     sen = 0\n",
      "#     des = 0\n",
      "#     fam = 0\n",
      "#     jo = 0\n",
      "#     mon = 0\n",
      "#     stu = 0\n",
      " \n",
      "#     for word in words:\n",
      "#         try:\n",
      "#             sen += scores[word]\n",
      "#             if word in desire:\n",
      "#                 des += 1\n",
      "#             if word in family:\n",
      "#                 fam += 1\n",
      "#             if word in job:\n",
      "#                 jo += 1\n",
      "#             if word in money:\n",
      "#                 mon += 1\n",
      "#             if word in student:\n",
      "#                 stu += 1   \n",
      "#         except:\n",
      "#             continue\n",
      " \n",
      "#     sentiment[i] = sen\n",
      "#     desire_vec[i] = des\n",
      "#     family_vec[i] = fam\n",
      "#     job_vec[i] = jo\n",
      "#     money_vec[i] = mon\n",
      "#     student_vec[i] = stu\n",
      "#     upvotes_vec[i] = upvotes\n",
      "#     accountagerequest_vec[i] = accountagerequest\n",
      "#     accountageretrieval_vec[i] = accountageretrieval\n",
      "#     commentsretrieval_vec[i] = commentsretrieval\n",
      "#     flair_vec[i] = flair\n",
      "#     pizza_vec[i] = pizza\n",
      " \n",
      " \n",
      "# num.savetxt('test.txt',num.c_[sentiment,desire_vec,family_vec,job_vec,\n",
      "#                                 money_vec, student_vec,upvotes_vec,\n",
      "#                                 accountagerequest_vec,accountageretrieval_vec,\n",
      "#                                 commentsretrieval_vec,flair_vec,pizza_vec],fmt='%1d',delimiter=\",\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "0",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-45-3150052d4f7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"request_text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;31m#     upvotes = t[i][\"requester_upvotes_minus_downvotes_at_retrieval\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m#     accountagerequest = t[i][\"requester_account_age_in_days_at_request\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mc:\\Users\\Connie\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1676\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1677\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1678\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1680\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mc:\\Users\\Connie\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1683\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1685\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionaility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mc:\\Users\\Connie\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mc:\\Users\\Connie\\Anaconda\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   2563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2564\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2565\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2566\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2567\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mc:\\Users\\Connie\\Anaconda\\lib\\site-packages\\pandas\\core\\index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[0mloc\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0munique\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly\u001b[0m \u001b[0mslice\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \"\"\"\n\u001b[1;32m-> 1181\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mc:\\Users\\Connie\\Anaconda\\lib\\site-packages\\pandas\\index.pyd\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3656)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32mc:\\Users\\Connie\\Anaconda\\lib\\site-packages\\pandas\\index.pyd\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3534)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32mc:\\Users\\Connie\\Anaconda\\lib\\site-packages\\pandas\\hashtable.pyd\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:11911)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32mc:\\Users\\Connie\\Anaconda\\lib\\site-packages\\pandas\\hashtable.pyd\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:11864)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;31mKeyError\u001b[0m: 0"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "import re\n",
      "import sys\n",
      "reload(sys)\n",
      "sys.setdefaultencoding('utf-8')\n",
      " \n",
      "# AFINN-111 is as of June 2011 the most recent version of AFINN\n",
      "filenameAFINN = 'AFINN-111.txt'\n",
      "afinn = dict(map(lambda (w, s): (w, int(s)), [ \n",
      "            ws.strip().split('\\t') for ws in open(filenameAFINN) ]))\n",
      " \n",
      "# Word splitter pattern\n",
      "pattern_split = re.compile(r\"\\W+\")\n",
      " \n",
      "def sentiment(text):\n",
      "    \"\"\"\n",
      "    Returns a float for sentiment strength based on the input text.\n",
      "    Positive values are positive valence, negative value are negative valence. \n",
      "    \"\"\"\n",
      "    words = pattern_split.split(text.lower())\n",
      "    sentiments = map(lambda word: afinn.get(word, 0), words)\n",
      "    if sentiments:\n",
      "        # How should you weight the individual word sentiments? \n",
      "        # You could do N, sqrt(N) or 1 for example. Here I use sqrt(N)\n",
      "        sentiment = float(sum(sentiments))/math.sqrt(len(sentiments))\n",
      "        \n",
      "    else:\n",
      "        sentiment = 0\n",
      "    return sentiment\n",
      " \n",
      " \n",
      " \n",
      "if __name__ == '__main__':\n",
      "    # Single sentence example:\n",
      "    text = \"Finn is stupid and idiotic\"\n",
      "    print(\"%6.2f %s\" % (sentiment(text), text))\n",
      "    \n",
      "    # No negation and booster words handled in this approach\n",
      "    text = \"Finn is only a tiny bit stupid and not idiotic\"\n",
      "    print(\"%6.2f %s\" % (sentiment(text), text))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}